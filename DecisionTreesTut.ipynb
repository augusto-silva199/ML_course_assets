{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM6UptiSLr4vWOnPFXgO903",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/augusto-silva199/ML_course_assets/blob/main/DecisionTreesTut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üå≤ A Tutorial on Decision Trees\n",
        "---\n",
        "> **Author:** Augusto Silva  \n",
        "> **Version:** 1.0 | **Date:** February 2026  \n",
        "> *Developed with the support of Gemini AI*\n",
        "\n",
        "---\n",
        "### üß¨ Clinical Context\n",
        "This tutorial introduces **Decision Trees (DTs)** as transparent \"Classifier Engines.\" Unlike \"black-box\" AI, DTs mirror the logical flow of medical decision-making.\n",
        "\n",
        "**Note:** We are utilizing a \"well-behaved\" version of the Wisconsin Breast Cancer dataset (balanced classes, no missing values) to focus specifically on the mechanics of Gini Impurity and Entropy."
      ],
      "metadata": {
        "id": "rWWdHeGZraLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üõ†Ô∏è Setup\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "\n",
        "# Define the button\n",
        "setup_button = widgets.Button(\n",
        "    description='Initialize Environment',\n",
        "    button_style='info',\n",
        "    icon='gears'\n",
        ")\n",
        "out = widgets.Output()\n",
        "\n",
        "def on_setup_clicked(b):\n",
        "    with out:\n",
        "        clear_output()\n",
        "        print(\"‚è≥ Loading medical AI libraries...\")\n",
        "\n",
        "        # The actual heavy lifting\n",
        "        global pd, np, plt, sns, train_test_split, DecisionTreeClassifier\n",
        "        import pandas as pd\n",
        "        import numpy as np\n",
        "        import matplotlib.pyplot as plt\n",
        "        import seaborn as sns\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        from sklearn.tree import DecisionTreeClassifier\n",
        "        from sklearn.metrics import accuracy_score\n",
        "\n",
        "        print(\"‚úÖ Success: Libraries imported.\")\n",
        "\n",
        "setup_button.on_click(on_setup_clicked)\n",
        "display(setup_button, out)"
      ],
      "metadata": {
        "id": "8ea9ThNNiGBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General Concepts\n",
        "\n",
        "Decision Trees are a widely used methodology in machine learning to solve classification and regression problems. The model is organized in the form of a hierarchical structure consisting of nodes and branches, where each node represents a decision based on a data attribute.\n",
        "This method stands out for its interpretability, conceptual simplicity and ability to model nonlinear relationships between variables. It is an interesting starting point for medical contexts where decision making workflows often appear to depend on decision trees."
      ],
      "metadata": {
        "id": "pjHH0i7aJu3_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/augusto-silva199/ML_course_assets/main/Figs/DT/examplemedical.png\" width=\"400\">\n",
        "  <br>\n",
        "  <em>Figure 1: A sample medical Decision Tree</em>\n",
        "</p>"
      ],
      "metadata": {
        "id": "OGWceCPICi6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tree structure\n",
        "A tree is composed of:\n",
        "*   A Root node: the starting point, where the first division of the data is made.\n",
        "*   Internal nodes: points where additional decisions occur.\n",
        "*   Leaves: terminal nodes that represent the predicted class (in the classification) or a numerical value (in the regression).\n",
        "*   Branches: paths that represent the result of the decisions made at each node.\n",
        "\n",
        "So at each node a subset partition is performed considering a decision rule. A subset is made more pure if it contains even more elements of a class or of an numeric interval.\n",
        "So the criteria to make a proper split is to maximize the purity of the subsets created."
      ],
      "metadata": {
        "id": "itlKmZtrMkKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/augusto-silva199/ML_course_assets/main/Figs/DT/IdealDTree.png\" width=\"700\">\n",
        "  <br>\n",
        "  <em>Figure 2: Left: An abstract two feature Decision Tree with 4 leaf nodes (classes). Right: Ideal feature space partioning. </em>\n",
        "</p>"
      ],
      "metadata": {
        "id": "C2Guxh2Tj0GI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split criteria\n",
        "In the learning phase at each node, one feature of the trining dataset is chosen to split training examples into distinct classes as much as possible. So a DT is grown by spliting the nodes up to a point where the subsets are clearly dominated by a class. Once the leaning is finished prediction may carried out. It just follows a unique path from root to a leaf (class)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/augusto-silva199/ML_course_assets/main/Figs/DT/Goalofsplit.png\" width=\"500\">\n",
        "  <br>\n",
        "  <em>Figure 3: Testing decision rules. </em>\n",
        "</p>\n",
        "\n",
        "Decision tree algorithms (such as CART - Classification and Regression Trees ) select the best split based on **impurity** measures.\n",
        "The two most commonly used impurity metrics in classification are Gini impurity and Entropy impurity.\n",
        "## Gini impurity\n",
        "The Gini impurity test assesses the degree of mixing between classes in a dataset. The lower the Gini value, the more homogeneous (purer) the dataset.\n",
        "Mathematically, the Gini Index represents the probability of misclassifying a randomly chosen element from the set if it were randomly labeled according to the distribution of labels in the subset. For a set of data with $N$ classes, let $p_i$ be the probability (or proportion) of an item belonging to class $i$. The Gini Index $G$ is defined as:\n",
        "$$G = \\sum_{i=1}^{N} p_i (1 - p_i)$$Since $\\sum p_i = 1$, we can simplify this to:\n",
        "$$G = 1 - \\sum_{i=1}^{N} p_i^2$$\n",
        "\n",
        "### A clinical example for breast masses\n",
        "Assume two classes in a large number of mammography cases: Malignant (M) and Benign (B). Let $p_1$ be the probability of Malignant. Let $p_2$ be the probability of Benign. The formula becomes:\n",
        "$$G = 1 - (p_M^2 + p_B^2)$$\n",
        "**Case A**: Perfect Purity (The Goal)\n",
        "\n",
        "If a node subset contains only Malignant cases:\n",
        "$$p_M = 1.0, p_B = 0$$\n",
        "$$G = 1 - (1^2 + 0^2) = \\mathbf{0}$$\n",
        "**Case B**: Maximum Impurity (The \"Coin Toss\")\n",
        "\n",
        "If a node subset is perfectly balanced (50/50):\n",
        "$$p_M = 0.5, p_B = 0.5$$\n",
        "$$G = 1 - (0.5^2 + 0.5^2) = 1 - (0.25 + 0.25) = \\mathbf{0.5}$$\n",
        "\n",
        "### Decreasing Impurity\n",
        "So the DT algorithm at each node seeks to split to more pure children nodes. So the optimal split will attain a maximum impurity decrease. For example in a case of a binary split examining a feature \"lesion diameter > T cm\" the impurity deacrease is\n",
        "$$\\Delta G = G_{parent} - \\sum_{k=1}^{2} \\frac{N_{subset_k}}{N_{parent}} G_{subset_k}$$\n",
        "The algorithm will look for the range of values in the \"lesion diameter\" feature and determines the T value that leads to best impurity decrease for this partiuclar decision rule.\n",
        "\n",
        "\n",
        "## Entropy\n",
        "Entropy measures the randomness or uncertainty or \"chaotic status\" of a set  of clinical data. In a binary classification task (like Malignant vs. Benign), the Entropy $H(S)$ of a set $S$ is defined by the following equation:\n",
        "$$H(S) = - \\sum_{i=1}^{c} p_i \\log_2(p_i)$$\n",
        "Where:\n",
        "*   $S$: The current subset of patient data.\n",
        "*   $c$: The number of classes (in this case, $c = 2$)\n",
        "*   $p_i$: The proportion (probability) of samples belonging to class $i$ in the set $S$.  \n",
        "\n",
        "### Information Gain\n",
        "During a split at a node we seek to gain information in the sense that the resulytig subsets are less entropic. In plays the same role as impurity decreasing with the Gini index. They the same functional definition\n",
        "$$\\Delta H = H_{parent} - \\sum_{k=1}^{2} \\frac{N_{subset_k}}{N_{parent}} H_{subset_k}$$\n",
        "\n",
        "Information Gain may represent the reduction in diagnostic uncertainty achieved by asking a specific question (e.g., Is the margin irregular?). The higher the gain, the more 'useful' that feature is for the final diagnosis."
      ],
      "metadata": {
        "id": "kKBtyxp4nT2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gini vs Entropy\n",
        "In Decision Trees, both Gini and Entropy serve the same purpose: they are objective functions used to measure the \"disorder\" in a group of patients. The algorithm uses these metrics to decide where to place its membership test (the split)\n",
        "\n",
        "$$\\begin{array}{|l|l|l|}\n",
        "\\hline\n",
        "\\mathbf{Feature} & \\mathbf{Gini \\ Impurity} & \\mathbf{Information \\ Entropy} \\\\ \\hline\n",
        "\\text{Focus} & \\text{Misclassification Probability} & \\text{Uncertainty / Chaos} \\\\ \\hline\n",
        "\\text{Math Definition} & G = 1 - \\sum p_i^2 & H = -\\sum p_i \\log_2(p_i) \\\\ \\hline\n",
        "\\text{Peak Value} & 0.5 \\text{ (Total Mix)} & 1.0 \\text{ (Total Mix)} \\\\ \\hline\n",
        "\\text{Clinical Analogy} & \\text{\"Random Guessing Risk\"} & \\text{\"Diagnostic Noise Level\"} \\\\ \\hline\n",
        "\\text{Goal} & \\text{Maximize Impurity Decrease } (\\Delta G) & \\text{Maximize Information Gain } (IG) \\\\ \\hline\n",
        "\\text{Computation} & \\text{Fast (Quadratic)} & \\text{Slower (Logarithmic)} \\\\ \\hline\n",
        "\\end{array}$$\n",
        "\n",
        "Clinical insights:\n",
        "\n",
        "*   GINI: \"How likely am I to be wrong?\"\n",
        "*   Entropy: \"How much more do I know now?\"\n",
        "*   Neither is \"better.\" They are different rulers measuring the same \"Diagnostic Clarity.\" In clinical practice, if a feature is a strong predictor (like a BI-RADS 5 score), both Gini and Entropy will identify it as the best split immediately.\n",
        "\n"
      ],
      "metadata": {
        "id": "mhLdUP-7tlRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About data types\n",
        "One of the greatest strengths of a Decision Tree (DT) in a clinical setting is its \"omnivore\" nature‚Äîit handles various data types with almost zero pre-processing, which mimics how a radiologist combines different types of information.\n",
        "\n",
        "** Data Type Flexibility**: The \"Unfair Advantage\"Unlike many algorithms that require everything to be a specific type of number, DTs adapt their \"Membership Tests\" to the data type:\n",
        "\n",
        "*   Numerical (Continuous): As we discussed, the DT finds a threshold (e.g., $Radius > 14.5\\text{ mm}$) to split the data.\n",
        "*   Categorical (Ordinal/Nominal): For features like \"Tissue Density\" (Low, Medium, High) or \"Shape\" (Round, Irregular), the tree simply groups the categories into subsets that maximize purity\n",
        "\n",
        "*   No Scaling Required: Because the tree looks at one feature at a time to make a split, it doesn't care if one feature is measured in millimeters and\n",
        "\n",
        "$$\\begin{array}{|l|l|l|l|}\n",
        "\\hline\n",
        "\\mathbf{Data \\ Type} & \\mathbf{Raw \\ Input} & \\mathbf{Membership \\ Rule \\ (The \\ \"Set\")} & \\mathbf{Logic \\ Type} \\\\ \\hline\n",
        "\\text{Numerical} & 14.8 \\text{ mm} & x \\in \\{ \\text{all values } \\le 15 \\} & \\text{Boundary Split} \\\\ \\hline\n",
        "\\text{Ordinal} & \\text{BI-RADS 3} & x \\in \\{ \\text{Score 1, 2, 3} \\} & \\text{Range Split} \\\\ \\hline\n",
        "\\text{Categorical} & \\text{\"Irregular\"} & x \\in \\{ \\text{\"Irregular\", \"Spiculated\"} \\} & \\text{Group Split} \\\\ \\hline\n",
        "\\end{array}$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**The Probabilistic Starting Point**\n",
        "A Decision Tree is essentially a machine that converts Global Probabilities into Local Certainty.\n",
        "\n",
        "Before any splits occur, every patient has the same \"Global\" probability of being Malignant (e.g., the prevalence in your dataset). If the dataset is 30% Malignant, your starting point is $p = 0.3$.\n",
        "\n",
        "**The Membership Filter**\n",
        "\n",
        "Each split is a filter. By asking a question ($Area > 500$), the model creates two new \"Sets.\n",
        "\n",
        "*   Set A: Patients who met the criteria.\n",
        "*   Set B: Patients who did not.\n",
        "\n",
        "**The Probability Shift**\n",
        "Inside these new sets, the Underlying Probability changes.\n",
        "\n",
        "*   In Set A (large area), the Malignant probability might jump to $p = 0.85$\n",
        "*   In Set B (small area), it might drop to $p = 0.05$.\n"
      ],
      "metadata": {
        "id": "IVtRyEu6LKvp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prunning\n",
        "\n",
        "Growing trees to make predictions within underlying local probability spaces should be a controlled process for the sake of robustness. Pruning is an algorithmic way of controlling tree growth.\n",
        "Pruning is a preventive or \"therapeutic\" measure to ensure quality control and robustness\n",
        "\n",
        "The goal of pruning is to achieve Parsimony. In radiography, we don't want a model that needs 50 different measurements to decide if a lesion is malignant; we want the 3 to 5 most robust indicators that work for every patient, not just the ones in our training set.\n",
        "\n",
        "In clinical AI, we must decide when the \"Information Gain\" from a split is no longer representing a medical truth, but rather statistical noise.\n",
        "\n",
        "$$\\begin{array}{|l|l|l|}\n",
        "\\hline\n",
        "\\mathbf{Strategy} & \\mathbf{Mechanism} & \\mathbf{Clinical \\ Analogy} \\\\ \\hline\n",
        "\\text{Pre-Pruning} & \\text{Stop-growth rules during training.} & \\text{Setting a time limit on a diagnostic exam.} \\\\ \\hline\n",
        "\\text{Post-Pruning} & \\text{Trimming branches after full growth.} & \\text{Editing a detailed report for clarity.} \\\\ \\hline\n",
        "\\end{array}$$\n",
        "\n",
        "**Pre-Pruning (Early Stopping)**\n",
        "\n",
        "Pre-pruning is the most common method used in teaching. You set \"Stop Signs\" (Hyperparameters) that prevent the tree from becoming too deep or complex.\n",
        "\n",
        "\n",
        "*   $\\texttt{max_depth}$: Limits the number of \"questions\" in the sequence.\n",
        "*   $\\texttt{min_samples_leaf}$: Ensures every diagnostic \"bucket\" has a statistically significant number of patients (e.g., at least 5-10).\n",
        "\n",
        "*   $\\texttt{min_impurity_decrease}$:  Only allows a split if the \"Information Gain\" is higher than a certain threshold.\n",
        "\n",
        "Just as we limit radiation dose to what is \"As Low As Reasonably Achievable\" (ALARA), we limit tree growth to what is \"As Simple As Reasonably Accurate.\"\n",
        "\n",
        "**Post-Pruning (Cost-Complexity)**\n",
        "\n",
        "Post-pruning allows the tree to grow to its maximum potential (where every leaf is pure), and then systematically removes branches that do not significantly improve predictive power.\n",
        "\n",
        "\n",
        "\n",
        "*   $\\alpha$ (Complexity Parameter): A mathematical penalty added to the tree's score for every leaf it has.  \n",
        "*   The Goal: Find the smallest tree that maintains the highest accuracy on unseen data\n",
        "\n",
        "$$\\text{Cost}(T) = \\text{Error}(T) + \\alpha |T|$$\n",
        "Where $|T|$ is the number of terminal leaves.\n",
        "\n",
        "$$\\begin{array}{|l|l|l|}\n",
        "\\hline\n",
        "\\mathbf{Constraint} & \\mathbf{Mechanism} & \\mathbf{Clinical \\ Result} \\\\ \\hline\n",
        "\\texttt{max\\_depth} & \\text{Limits vertical growth} & \\text{Prevents over-specialized rules} \\\\ \\hline\n",
        "\\texttt{min\\_samples\\_leaf} & \\text{Ensures minimum subset size} & \\text{Guarantees statistical significance} \\\\ \\hline\n",
        "\\texttt{ccp\\_alpha} & \\text{Applies a penalty to complexity} & \\text{Surgically removes weak branches} \\\\ \\hline\n",
        "\\end{array}$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gsPY0y54T-ko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Robustness and Generalization\n",
        "\n",
        "This table summarizes how data characteristics and model constraints interact to produce a trustworthy diagnostic tool.\n",
        "\n",
        "$$\\begin{array}{|l|l|l|}\n",
        "\\hline\n",
        "\\mathbf{Pillar} & \\mathbf{Technical \\ Requirement} & \\mathbf{Clinical \\ Importance} \\\\ \\hline\n",
        "\\text{Robustness} & \\text{High } N \\text{ (Sample Size)} & \\text{Stability: Prevents rules based on outliers.} \\\\ \\hline\n",
        "\\text{Generalization} & \\text{Pruning (e.g., } \\texttt{max\\_depth}\\text{)} & \\text{Reliability: Ensures logic works on new patients.} \\\\ \\hline\n",
        "\\text{Quality Control} & \\text{Impurity Metrics (Gini/Entropy)} & \\text{Objectivity: Standardizes the \"Membership Tests.\"} \\\\ \\hline\n",
        "\\text{Demographics} & \\text{Representative Distribution} & \\text{Equity: Avoids bias against specific subgroups.} \\\\ \\hline\n",
        "\\end{array}$$\n",
        "\n",
        "**Robustness**: The Law of Large Numbers\n",
        "\n",
        "A \"robust\" model is one where the splits do not change drastically if you add or remove a few patients.\n",
        "* The Math: Robustness depends on having enough samples in each node to ensure the Underlying Probabilities ($p_i$) are accurate.\n",
        "* The Clinical Risk: Small datasets lead to \"Spurious Correlations\"‚Äîfinding a \"rule\" that only exists in your specific training set.\n",
        "\n",
        "**Generalization**: The \"Parsimony\" Principle\n",
        "Generalization is the model's ability to perform as well in the \"Real World\" as it did in the \"Lab.\"\n",
        "\n",
        "* The Therapy: We use Preventive measures (max_depth) and Therapeutic measures (ccp_alpha) to stop the tree from \"memorizing\" the training data.\n",
        "* The Goal: A simpler tree is almost always more generalizable than a complex one.\n",
        "\n",
        "**Dataset Demographics & Probability Distribution**\n",
        "The \"Intelligence\" of the tree is limited by the Diversity of the input.\n",
        "\n",
        "* The Bias Trap: If your dataset demographics are skewed (e.g., only patients over 60), the probability distributions the tree learns for \"Malignancy\" will not translate to a younger population.\n",
        "* Class Imbalance: If 99% of your data is Benign, the tree will have a high \"Global Purity\" by simply ignoring the Malignant cases. We correct this using class_weight='balanced'.\n",
        "\n",
        "In Radiology, we don't trust a single pixel; we look for patterns across the whole image. Similarly, in AI, we don't trust a single split; we ensure that split is supported by Robust data, a Balanced distribution, and Pruned logic."
      ],
      "metadata": {
        "id": "ukQoOymnnun6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Case\n",
        "\n",
        "The [Wisconsin Diagnostic Breast Cancer](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic) (WDBC) dataset is a widely used, publicly available binary classification dataset from the UCI Machine Learning Repository containing 569 instances (357 benign, 212 malignant). It features 30 numerical, real-valued features computed from digitized images of fine needle aspirate (FNA) of breast masses, representing characteristics of cell nuclei.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/augusto-silva199/ML_course_assets/main/Figs/DT/BreastCancerNucleus.png\" width=\"400\">\n",
        "  <br>\n",
        "  <em>Figure 4: A sample case with several outlined nucleus\n",
        "  </em>\n",
        "</p>\n",
        "\n",
        "\n",
        "**Key Details of the WDBC Dataset**\n",
        "* Source: Collected in the early 1990s by Dr. William H. Wolberg at the University of Wisconsin Hospital.\n",
        "* Classes: 569 total instances: 357 benign (B) and 212 malignant (M).\n",
        "* Features: 30 numerical features (10 real-valued features, each with mean, standard error, and \"worst\" value) calculated from digitized images.\n",
        "* Target: Binary classification: Malignant (M) or Benign (B).\n",
        "* Usage: Frequently used for supervised machine learning, specifically in SVM, KNN, and decision tree classifiers to predict breast cancer.\n",
        "* Features Included:\n",
        "Radius (mean of distances from center to points on the perimeter)\n",
        "Texture (standard deviation of gray-scale values)\n",
        "Perimeter, Area, Smoothness, Compactness, Concavity, Concave points, Symmetry, and Fractal dimension.\n"
      ],
      "metadata": {
        "id": "7fevJ1zwL_F1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Data\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# 1. Define the Button\n",
        "load_button = widgets.Button(\n",
        "    description='Load Wisconsin Dataset',\n",
        "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Click to fetch data from GitHub',\n",
        "    icon='database'\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_button_clicked(b):\n",
        "    with output:\n",
        "        clear_output()\n",
        "        try:\n",
        "            # Replace 'YOUR_USERNAME' with your actual GitHub username\n",
        "            url = \"https://raw.githubusercontent.com/augusto-silva199/ML_course_assets/main/Datafiles/BreastC/breastc_data.csv\"\n",
        "\n",
        "            # Loading the data\n",
        "            global df\n",
        "            df = pd.read_csv(url)\n",
        "\n",
        "            print(\"‚úÖ Data Loaded Successfully!\")\n",
        "            print(f\"Total Patients: {df.shape[0]}\")\n",
        "            print(f\"Diagnostic Features: {df.shape[1] - 1}\")\n",
        "            display(df.head(5))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: Could not find the file. Check the URL path.\\n{e}\")\n",
        "\n",
        "load_button.on_click(on_button_clicked)\n",
        "\n",
        "# 2. Display the Interface\n",
        "display(load_button, output)"
      ],
      "metadata": {
        "id": "4cLmdFHSxryp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elementary Statistics"
      ],
      "metadata": {
        "id": "H0YkUu1Pxls8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the \"id\" column\"\n",
        "df = df.drop(columns=['id'])\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "Qlk4MohLxGN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Class Balance\n",
        "\n",
        "\n",
        "# 1. Define the UI Elements\n",
        "load_plot_button = widgets.Button(\n",
        "    description='Analyze Balance',\n",
        "    button_style='info',\n",
        "    layout=widgets.Layout(width='250px'),\n",
        "    icon='chart-bar'\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def load_and_visualize(b):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        try:\n",
        "\n",
        "            # Setting up the visual style\n",
        "            sns.set_theme(style=\"whitegrid\")\n",
        "            fig, ax = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "            # 2. Create the Seaborn Bar Plot\n",
        "            # Assuming your target column is named 'diagnosis'\n",
        "            sns.countplot(data=df,\n",
        "                         x='diagnosis',\n",
        "                         hue='diagnosis',    # Link colors to the diagnosis categories\n",
        "                         palette=['#3498db', '#e74c3c'],\n",
        "                         legend=False,       # Remove the redundant legend\n",
        "                         ax=ax)\n",
        "\n",
        "            plt.title('Clinical Dataset Balance: Benign vs. Malignant', fontsize=9)\n",
        "            plt.xlabel('Diagnosis', fontsize=9)\n",
        "            plt.ylabel('Patient Count', fontsize=9)\n",
        "\n",
        "            # Adding percentage labels on top of bars for \"Robustness\" context\n",
        "            total = len(df)\n",
        "            for p in ax.patches:\n",
        "                percentage = f'{100 * p.get_height() / total:.1f}%'\n",
        "                ax.annotate(percentage, (p.get_x() + p.get_width() / 2., p.get_height()/2),\n",
        "                            ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: Check the GitHub path or Column names.\\n{e}\")\n",
        "\n",
        "load_plot_button.on_click(load_and_visualize)\n",
        "\n",
        "# 3. Display\n",
        "display(load_plot_button, output_area)"
      ],
      "metadata": {
        "id": "j5a79SYZ1VkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visual Insights"
      ],
      "metadata": {
        "id": "DfKf5PclYF-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Histograms\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact\n",
        "\n",
        "def plot_feature_distribution(feature):\n",
        "    plt.figure(figsize=(5, 3))\n",
        "\n",
        "    # Create the overlapping histograms\n",
        "    sns.histplot(data=df, x=feature, hue='diagnosis',\n",
        "                 palette=['#3498db', '#e74c3c'],\n",
        "                 kde=True, element=\"step\", common_norm=False)\n",
        "\n",
        "    # Formatting for clinical clarity\n",
        "    plt.title(f'Diagnostic Distribution: {feature}', fontsize=12)\n",
        "    plt.xlabel(f'{feature} Value', fontsize=12)\n",
        "    plt.ylabel('Patient Frequency', fontsize=12)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# Create the dropdown menu using the column names (excluding 'diagnosis' and 'id')\n",
        "features_list = [col for col in df.columns if col not in ['diagnosis', 'id']]\n",
        "\n",
        "print(\"üìä Select a Clinical Predictor to analyze the class overlap:\\n\")\n",
        "interact(plot_feature_distribution, feature=features_list);"
      ],
      "metadata": {
        "id": "L-UuhtnLZD9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scatter plots\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact\n",
        "\n",
        "def plot_2d_interaction(feat_x, feat_y):\n",
        "    plt.figure(figsize=(5, 3))\n",
        "\n",
        "    # Create the scatter plot\n",
        "    sns.scatterplot(data=df, x=feat_x, y=feat_y, hue='diagnosis',\n",
        "                    palette=['#3498db', '#e74c3c'],\n",
        "                    alpha=0.7, s=60, edgecolor='w')\n",
        "\n",
        "    # Clinical Aesthetics\n",
        "    plt.title(f'Diagnostic Space: {feat_x} vs {feat_y}', fontsize=10)\n",
        "    plt.xlabel(feat_x, fontsize=10)\n",
        "    plt.ylabel(feat_y, fontsize=10)\n",
        "    plt.legend(title='Diagnosis', loc='upper right')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "# List of columns to choose from\n",
        "features_list = [col for col in df.columns if col not in ['diagnosis', 'id']]\n",
        "\n",
        "print(\"üéØ Select two predictors to visualize the Decision Space:\\n\")\n",
        "interact(plot_2d_interaction,\n",
        "         feat_x=widgets.Dropdown(options=features_list, value='radius_mean'),\n",
        "         feat_y=widgets.Dropdown(options=features_list, value='texture_mean'));"
      ],
      "metadata": {
        "id": "12hKj3JmYcis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and test"
      ],
      "metadata": {
        "id": "OeVckZBJa_3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def train_dt(criterion, max_depth, test_size):\n",
        "    # 1. Prepare Data\n",
        "    X = df.drop(columns=['diagnosis'])\n",
        "    y = df['diagnosis']\n",
        "\n",
        "    # 2. The Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=42\n",
        "    )\n",
        "\n",
        "    # 3. The Classifier\n",
        "    model = DecisionTreeClassifier(\n",
        "        criterion=criterion,\n",
        "        max_depth=max_depth,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 4. Evaluation\n",
        "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
        "    test_acc = accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "    # Visual Output\n",
        "    print(f\"\\nüè• CLINICAL MODEL AUDIT\\n\")\n",
        "    print(f\"{'='*30}\")\n",
        "    print(f\"Logic: {criterion.title()} | Max Depth: {max_depth} | Test Split: {test_size*100}%\\n\")\n",
        "    print(f\"{'-'*30}\")\n",
        "    print(f\"‚úÖ Training Accuracy: {train_acc:.2%}\")\n",
        "    print(f\"üöÄ Testing Accuracy:  {test_acc:.2%}\")\n",
        "\n",
        "    # Robustness Feedback\n",
        "    if train_acc > test_acc + 0.05:\n",
        "        print(\"\\n‚ö†Ô∏è STATUS: Overfitting. (The model is too 'narrow-minded')\")\n",
        "    elif train_acc < 0.85:\n",
        "        print(\"\\n‚ö†Ô∏è STATUS: Underfitting. (The model is too 'simplistic')\")\n",
        "    else:\n",
        "        print(\"\\nüíé STATUS: Robust. (Ideal balance for Clinical Use)\")\n",
        "\n",
        "# --- The \"Silent\" UI Logic ---\n",
        "# Define the controls manually to avoid the function signature printout\n",
        "style = {'description_width': 'initial'}\n",
        "criterion_sel = widgets.Dropdown(options=['gini', 'entropy'], value='gini', description='Criterion:', style=style)\n",
        "depth_sld = widgets.IntSlider(min=1, max=20, value=3, description='Max Depth:', style=style)\n",
        "test_sld = widgets.FloatSlider(min=0.1, max=0.5, step=0.05, value=0.3, description='Test Size %:', style=style)\n",
        "\n",
        "# Use interactive_output to link controls to the function without printing metadata\n",
        "ui = widgets.HBox([criterion_sel, depth_sld, test_sld])\n",
        "out = widgets.interactive_output(train_dt, {'criterion': criterion_sel, 'max_depth': depth_sld, 'test_size': test_sld})\n",
        "\n",
        "display(ui, out)"
      ],
      "metadata": {
        "id": "UKmczzvPcH-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance report"
      ],
      "metadata": {
        "id": "kBkDgbgpdRSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "def evaluate_performance(criterion, max_depth, test_size):\n",
        "    # 1. Setup & Train (Reusing our logic)\n",
        "    X = df.drop(columns=['diagnosis',])\n",
        "    y = df['diagnosis']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # 2. Confusion Matrix Calculation\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # 3. Visualization\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Heatmap\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
        "                xticklabels=['Benign', 'Malignant'],\n",
        "                yticklabels=['Benign', 'Malignant'])\n",
        "    ax1.set_title('Confusion Matrix (Clinical Audit)', fontsize=14)\n",
        "    ax1.set_xlabel('Predicted Diagnosis')\n",
        "    ax1.set_ylabel('Actual Ground Truth')\n",
        "\n",
        "    # Performance Report Table\n",
        "    report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
        "    report_df = pd.DataFrame(report_dict).transpose().round(3)\n",
        "\n",
        "    # Plotting the table on the second axis\n",
        "    ax2.axis('off')\n",
        "    table = ax2.table(cellText=report_df.values,\n",
        "                      colLabels=report_df.columns,\n",
        "                      rowLabels=report_df.index,\n",
        "                      loc='center', cellLoc='center')\n",
        "    table.set_fontsize(12)\n",
        "    table.scale(1, 2)\n",
        "    ax2.set_title('Metric Performance Table', fontsize=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Link back to the same interactive controls for seamless auditing\n",
        "interact_out = widgets.interactive_output(evaluate_performance,\n",
        "                                          {'criterion': criterion_sel,\n",
        "                                           'max_depth': depth_sld,\n",
        "                                           'test_size': test_sld})\n",
        "display(ui, interact_out)"
      ],
      "metadata": {
        "id": "mSCEoKYIdUrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ROC Curve\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "def plot_roc_curve(criterion, max_depth, test_size):\n",
        "    # 1. Setup & Train\n",
        "    X = df.drop(columns=['diagnosis'])\n",
        "    y = df['diagnosis'].map({'M': 1, 'B': 0}) # Convert to binary for ROC\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 2. Get Probabilities (Important: ROC uses probabilities, not just labels)\n",
        "    y_score = model.predict_proba(X_test)[:, 1]\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # 3. Plotting\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--') # The \"Random Chance\" line\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "    plt.title('ROC Analysis: Breast Cancer Diagnostic Power')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# Linking to the same UI\n",
        "roc_out = widgets.interactive_output(plot_roc_curve,\n",
        "                                    {'criterion': criterion_sel,\n",
        "                                     'max_depth': depth_sld,\n",
        "                                     'test_size': test_sld})\n",
        "display(ui, roc_out)"
      ],
      "metadata": {
        "id": "n7LIZNYpfbFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tree layout\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "def visualize_clinical_tree(criterion, max_depth, test_size):\n",
        "    # 1. Setup & Train (Standard Audit Logic)\n",
        "    X = df.drop(columns=['diagnosis'])\n",
        "    y = df['diagnosis']\n",
        "    feature_names = X.columns.tolist()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 2. Plotting the Flowchart\n",
        "    plt.figure(figsize=(20, 10), dpi=100)\n",
        "    plot_tree(model,\n",
        "              feature_names=feature_names,\n",
        "              class_names=['Benign', 'Malignant'],\n",
        "              filled=True,\n",
        "              rounded=True,\n",
        "              fontsize=10,\n",
        "              precision=2)\n",
        "\n",
        "    plt.title(f\"Diagnostic Logic Flow (Depth: {max_depth})\", fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "# Connect to our dashboard UI\n",
        "tree_out = widgets.interactive_output(visualize_clinical_tree,\n",
        "                                     {'criterion': criterion_sel,\n",
        "                                      'max_depth': depth_sld,\n",
        "                                      'test_size': test_sld})\n",
        "display(ui, tree_out)"
      ],
      "metadata": {
        "id": "kwAJ75jWgnXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feature Importance\n",
        "import numpy as np\n",
        "\n",
        "def plot_importance(criterion, max_depth, test_size):\n",
        "    # 1. Train the model using the current slider values\n",
        "    X = df.drop(columns=['diagnosis'])\n",
        "    y = df['diagnosis']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 2. Extract Importances\n",
        "    importances = model.feature_importances_\n",
        "    indices = np.argsort(importances)[-10:]  # Show only top 10 for clarity\n",
        "\n",
        "    # 3. Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title('Clinical Weight: Top 10 Diagnostic Predictors', fontsize=10)\n",
        "    plt.barh(range(len(indices)), importances[indices], color='#3498db', align='center')\n",
        "    plt.yticks(range(len(indices)), [X.columns[i] for i in indices])\n",
        "    plt.xlabel('Relative Importance (Gini Reduction)')\n",
        "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Link to UI\n",
        "imp_out = widgets.interactive_output(plot_importance,\n",
        "                                    {'criterion': criterion_sel,\n",
        "                                     'max_depth': depth_sld,\n",
        "                                     'test_size': test_sld})\n",
        "display(ui, imp_out)"
      ],
      "metadata": {
        "id": "NbWeAsEMmBQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Remarks\n",
        "\n",
        "This exercise serves as a fundamental template for understanding how Machine Learning translates into Clinical Decision Support. While we have used the Wisconsin Breast Cancer dataset to build our \"Engine,\" the logic applies to almost any diagnostic pathway in radiology and medicine.\n",
        "\n",
        "üß¨ Summary of our Findings\n",
        "* Algorithmic Transparency: We moved from a \"Black Box\" to a visible flowchart. The Decision Tree mimics the \"If-Then\" logic used by clinicians during differential diagnosis.\n",
        "\n",
        "* The Power of Simplicity: We saw that a well-behaved dataset allows a simple classifier to achieve high accuracy without needing complex neural networks.\n",
        "\n",
        "* Quality Control through Pruning: We demonstrated that \"more depth\" isn't always better. Restricting the tree (Pruning) ensures the model learns stable clinical patterns rather than memorizing individual patient \"noise.\"\n",
        "\n",
        "üèõÔ∏è Why this Dataset is the \"Perfect Lab\"\n",
        "It is important to note that this specific exercise used a \"Well-Behaved\" dataset, which is rare in real-world clinical practice:\n",
        "\n",
        "* Class Balance: The split between Benign and Malignant cases was relatively even (~60/40). In real screening environments, the \"Disease\" class might be less than 1%, requiring much more advanced \"Class Weighting\" techniques.\n",
        "\n",
        "* Data Integrity: There were no missing values. In a typical hospital database, you would encounter missing labels, corrupted images, or incomplete patient histories that require significant \"Data Cleaning\" before a tree can be grown.\n",
        "\n",
        "* Linear Separability: Many features in this dataset (like concave_points) have a very clear \"Threshold\" that separates the classes, which is why our ROC curve showed such a strong \"Knee\" early on.\n",
        "\n",
        "* Feature Importance is specific to this dataset ‚Äî in a different patient population, the most important \"predictor\" might change.\n",
        "\n"
      ],
      "metadata": {
        "id": "dvdQWhnpkfl5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qST7olZ58k7e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}